{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA Regularization - \n",
    "# 1. Loading AUTO.CSV data\n",
    "# 2. It has 398 rows with missing values against \"horsepower\" > regularizing to remove all null and missing values and get array of 392X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement horsepower  weight  acceleration  year  \\\n",
       "0  18.0          8         307.0        130    3504          12.0    70   \n",
       "1  15.0          8         350.0        165    3693          11.5    70   \n",
       "2  18.0          8         318.0        150    3436          11.0    70   \n",
       "3  16.0          8         304.0        150    3433          12.0    70   \n",
       "4  17.0          8         302.0        140    3449          10.5    70   \n",
       "\n",
       "   origin                       name  \n",
       "0       1  chevrolet chevelle malibu  \n",
       "1       1          buick skylark 320  \n",
       "2       1         plymouth satellite  \n",
       "3       1              amc rebel sst  \n",
       "4       1                ford torino  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.read_csv(\"Auto.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"horsepower\"].isnull().values.any()\n",
    "df[\"horsepower\"] = pandas.to_numeric( df[\"horsepower\"],errors = 'corece')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUES 2 > \n",
    "\n",
    "# Use the Auto data set. Create a new variable high that takes values high :=(1 if mpg ≥ 23 0 otherwise (i.e., if mpg ≤ 22). Apply your program to the Auto data set and new variable to predict high given horsepower, weight, year, and origin. (In other words, high is the label and horsepower, weight, year, and origin are the attributes.) Since origin is a qualitative variable, you will have to create appropriate dummy variables. Normalize the attributes, as described in Lab Worksheet 4, Section 5 or Exercise 9 (or Section 4.6.6 of [2]).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Creating Dummy variables against \"ORIGIN\", merging with the dataset and then deleting \"ORIGIN\" attribute from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>origin_1</th>\n",
       "      <th>origin_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>buick skylark 320</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>plymouth satellite</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>amc rebel sst</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>ford torino</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0    70   \n",
       "1  15.0          8         350.0       165.0    3693          11.5    70   \n",
       "2  18.0          8         318.0       150.0    3436          11.0    70   \n",
       "3  16.0          8         304.0       150.0    3433          12.0    70   \n",
       "4  17.0          8         302.0       140.0    3449          10.5    70   \n",
       "\n",
       "                        name  origin_1  origin_2  \n",
       "0  chevrolet chevelle malibu         1         0  \n",
       "1          buick skylark 320         1         0  \n",
       "2         plymouth satellite         1         0  \n",
       "3              amc rebel sst         1         0  \n",
       "4                ford torino         1         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_dummies(var):\n",
    "    # Getting the unique values in var and sort.\n",
    "    var_unique = var.unique()\n",
    "    var_unique.sort()\n",
    "    \n",
    "    dummy = pandas.DataFrame()\n",
    "    \n",
    "    # Looping through all but the last value.\n",
    "    for val in var_unique[:-1]:\n",
    "        # Which columns are equal to our unique value.\n",
    "        d = var == val\n",
    "        \n",
    "        # Making a new column with a dummy variable.\n",
    "        dummy[var.name + \"_\" + str(val)] = d.astype(int)\n",
    "    \n",
    "    # Return dataframe with our dummy variables.\n",
    "    return dummy\n",
    "\n",
    "# Making a copy of our auto dataframe to modify with dummy variables.\n",
    "modified_df = df.copy()\n",
    "\n",
    "# Making dummy varibles from the origin categories.\n",
    "origin_dummies = create_dummies(modified_df[\"origin\"])\n",
    "\n",
    "# Merging dummy varibles to our dataframe.\n",
    "modified_df = pandas.concat([modified_df, origin_dummies], axis=1)\n",
    "\n",
    "# Delete cylinders column as we have now explained it with dummy variables.\n",
    "del modified_df[\"origin\"]\n",
    "\n",
    "modified_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create a variable - 'HIGH' that has values high :=(1 if mpg ≥ 23 0 otherwise (i.e., if mpg ≤ 22)\n",
    "# Renaming it as Y - Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_high(var):\n",
    "    d=0\n",
    "    high = []\n",
    "    var = np.array(var)\n",
    "    for i in range(len(var)):\n",
    "        if (var[i] <= 22):\n",
    "            d=0\n",
    "            high.append(d)\n",
    "        else:\n",
    "            d=1\n",
    "            high.append(d)\n",
    "    high = np.array(high)\n",
    "    \n",
    "    return high\n",
    "\n",
    "# Making HIGH variable against mpg.\n",
    "Y = create_high(modified_df[\"mpg\"])\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Deleting all the additional attributes and keeping only 'HORSEPOWER, 'WEIGHT', 'YEAR', \"ORIGIN_1\" and 'ORIGIN_2' in X - (train + test ) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a copy of our auto dataframe to modify with dummy variables.\n",
    "modified_df1 = modified_df.copy()\n",
    "\n",
    "# Delete mpg,cylinders,displacement, acceleration,name column and we have only horsepower, weight, year \n",
    "#and origin(origin_1 and origin_2 as dummy variables) in X dataset.\n",
    "del modified_df1[\"mpg\"]\n",
    "del modified_df1[\"cylinders\"]\n",
    "del modified_df1[\"displacement\"]\n",
    "del modified_df1[\"acceleration\"]\n",
    "del modified_df1[\"name\"]\n",
    "\n",
    "X = np.array(modified_df1)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we have X -> with 5 attributes\n",
    "# Y > label (1,0 values)\n",
    "\n",
    "# 4. Normalize the attributes - X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_normed = (X - X.min(0)) / X.ptp(0)\n",
    "X_normed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUES 3 - Split the Data Set - Train and Test with pseudorandom number generator as MMDD - 830 (DOB - MMDDYY - 083090)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normed, Y, test_size = 0.5, random_state = 830)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Below function will perform the below task - \n",
    "\n",
    "# Ques 1 - Minimize the Objective Function.\n",
    "\n",
    "# Ques 4 - Train the algorithm on the train data using Independent Random Numbers in Range [-0.7 0.7].\n",
    "\n",
    "# Use Stopping Rule to stop Iterations.\n",
    "\n",
    "# Predict both train and test data and calculate MSE for both train and test data.\n",
    "\n",
    "# Results in Table produced in REPORT.PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "1406\n",
      "learning rate: 0.15\n",
      "3644\n",
      "learning rate: 0.02\n",
      "1853\n",
      "learning rate: 0.025\n",
      "1936\n",
      "learning rate: 0.01\n",
      "1406\n",
      "learning rate: 0.15\n",
      "3644\n",
      "learning rate: 0.02\n",
      "1853\n",
      "learning rate: 0.025\n",
      "1936\n",
      "learning rate: 0.01\n",
      "1406\n",
      "learning rate: 0.15\n",
      "3644\n",
      "learning rate: 0.02\n",
      "1853\n",
      "learning rate: 0.025\n",
      "1936\n",
      "learning rate: 0.01\n",
      "1406\n",
      "learning rate: 0.15\n",
      "3644\n",
      "learning rate: 0.02\n",
      "1853\n",
      "learning rate: 0.025\n",
      "1936\n",
      "TRAIN MSE\n",
      "[0.19387755102040816, 0.08163265306122448, 0.1326530612244898, 0.12244897959183673, 0.19387755102040816, 0.08163265306122448, 0.1326530612244898, 0.12244897959183673, 0.19387755102040816, 0.08163265306122448, 0.1326530612244898, 0.12244897959183673, 0.19387755102040816, 0.08163265306122448, 0.1326530612244898, 0.12244897959183673]\n",
      "TEST MSE\n",
      "[0.18877551020408162, 0.10714285714285714, 0.1377551020408163, 0.1326530612244898, 0.18877551020408162, 0.10714285714285714, 0.1377551020408163, 0.1326530612244898, 0.18877551020408162, 0.10714285714285714, 0.1377551020408163, 0.1326530612244898, 0.18877551020408162, 0.10714285714285714, 0.1377551020408163, 0.1326530612244898]\n"
     ]
    }
   ],
   "source": [
    "# --------------------------Sigmoid Function------------------------\n",
    "def sigmoid(z):\n",
    "    s= 1/(1 + np.exp(-z))\n",
    "    return s\n",
    "\n",
    "# ----------------------Forward and Backward Propogation alongwith Loss Function--------------------\n",
    "def propagate(w, b, X, Y):\n",
    "    \n",
    "    m = Y.shape[0]\n",
    "    # compute activation\n",
    "    A = sigmoid(np.dot(X,w))\n",
    "      \n",
    "    epsilon = 1e-5\n",
    "    cost = (-Y * np.log(A) - (1 - Y) * np.log(1 - A)).mean()\n",
    " \n",
    "    # derivatives\n",
    "    dz= (A - Y)/m\n",
    "    dz.shape\n",
    "    dw = np.dot(X.T, dz)\n",
    "    db = np.sum(dz)\n",
    "    cost = np.squeeze(cost)\n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "\n",
    "    return grads, cost\n",
    "\n",
    "# --------------------Prediction against the trained model--------------------\n",
    "def predict(w, b, X):\n",
    "\n",
    "    Y_prediction = []\n",
    "    w = w.reshape(X.shape[1], 1)\n",
    "    A = sigmoid(np.dot(X,w))  \n",
    "    Y_prediction = 1. * (A > 0.5)\n",
    "\n",
    "    return Y_prediction\n",
    "\n",
    "# ----Optimize function- first - propogate, find updated weights using Learning Rate and Implement stopping rule-----\n",
    "def optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost = False):\n",
    "\n",
    "    costs = []\n",
    "    tolerance = 0.002\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        m = Y_train.shape[0]\n",
    "        grads,cost = propagate(w, b, X_train, Y_train)\n",
    "        b = b - learning_rate*grads[\"db\"]\n",
    "        new_w = w - learning_rate*grads[\"dw\"]\n",
    "\n",
    "        # Stopping Rule\n",
    "        if np.sum(abs(new_w - w)) < tolerance:\n",
    "            print(i)\n",
    "            break\n",
    "        w = new_w\n",
    "\n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    return params, grads, costs\n",
    "\n",
    "# --------------Method for weight geenration and MSE calculation---------------\n",
    "def model(X_train, y_train, X_test, y_test, num_iterations, learning_rate, print_cost = False):\n",
    "    \n",
    "    #Bias\n",
    "    b = np.ones((X_train.shape[0], 1)) \n",
    "    X_train = np.concatenate((b, X_train), axis=1)\n",
    "    X_test = np.concatenate((b, X_test), axis=1)\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    #Independent number generation for weight between [-0.7 0.7]\n",
    "    w = np.random.uniform(low=-0.7,high=0.7,size=(X_train.shape[1],))\n",
    "\n",
    "    print(\"learning rate:\",learning_rate)\n",
    "    \n",
    "    # optimize and finding the model with best suited Weights and bias\n",
    "    parameters, grads, costs = optimize(w, b, X_train, y_train, num_iterations, learning_rate, print_cost = False)\n",
    "   \n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "\n",
    "    # Predict both train and test against optimized weights and Bias\n",
    "    Y_prediction_train = predict(w,b,X_train)\n",
    "    Y_prediction_test = predict(w,b,X_test)\n",
    "    \n",
    "    Y_hat_train = list(Y_prediction_train)\n",
    "    y_train_m = list(y_train)\n",
    "    y_test_m = list(y_test)\n",
    "    Y_hat_test = list(Y_prediction_test)  \n",
    "      \n",
    "    # MSE calculation - for both TRAIN and TEST\n",
    "    a=0\n",
    "    correct=0\n",
    "    for each_train in y_train_m:\n",
    "        if each_train-Y_hat_train[a]!=0:\n",
    "            correct+=1\n",
    "        a+=1\n",
    "    curr_mse_train = correct/len(y_train_m)\n",
    "    \n",
    "    a1=0\n",
    "    correct1=0\n",
    "    for each_test in y_test_m:\n",
    "        if each_test-Y_hat_test[a1]!=0:\n",
    "            correct1+=1\n",
    "        a1+=1\n",
    "    curr_mse_test = correct1/len(y_test_m)\n",
    "      \n",
    "    d = {\"train MSE\": curr_mse_train,\n",
    "        \"test MSE\": curr_mse_test}\n",
    "\n",
    "    return d\n",
    "\n",
    "\n",
    "# --------------------Main Call for functions implementation------------------\n",
    "result_train = []\n",
    "result_test = []\n",
    "\n",
    "# iterating over 1. different values of epochs and 2. different values of learning rate\n",
    "epochs = [5000,10000,6000,4000]\n",
    "lr_list = [0.01,0.15,0.02,0.025]\n",
    "for i in range(len(epochs)):\n",
    "    for j in range(len(lr_list)):\n",
    "        d = model(X_train, y_train, X_test, y_test, num_iterations = epochs[i], learning_rate = lr_list[j], print_cost = True)\n",
    "        result_train.append(d[\"train MSE\"])\n",
    "        result_test.append(d[\"test MSE\"])               \n",
    "\n",
    "print(\"TRAIN MSE\")\n",
    "print(result_train)\n",
    "print(\"TEST MSE\")\n",
    "print(result_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUES 6 - Running the Logistic Regression over fixed value of Learning Rate - 0.01 and Number of Iterations - 5000 with Stopping Rule\n",
    "# Running 100 times and presenting result in boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "1290\n",
      "learning rate: 0.01\n",
      "1302\n",
      "learning rate: 0.01\n",
      "1151\n",
      "learning rate: 0.01\n",
      "1074\n",
      "learning rate: 0.01\n",
      "1736\n",
      "learning rate: 0.01\n",
      "1310\n",
      "learning rate: 0.01\n",
      "1682\n",
      "learning rate: 0.01\n",
      "1135\n",
      "learning rate: 0.01\n",
      "1413\n",
      "learning rate: 0.01\n",
      "1339\n",
      "learning rate: 0.01\n",
      "1727\n",
      "learning rate: 0.01\n",
      "1858\n",
      "learning rate: 0.01\n",
      "1579\n",
      "learning rate: 0.01\n",
      "1375\n",
      "learning rate: 0.01\n",
      "1611\n",
      "learning rate: 0.01\n",
      "958\n",
      "learning rate: 0.01\n",
      "741\n",
      "learning rate: 0.01\n",
      "1601\n",
      "learning rate: 0.01\n",
      "1714\n",
      "learning rate: 0.01\n",
      "1565\n",
      "learning rate: 0.01\n",
      "1273\n",
      "learning rate: 0.01\n",
      "1623\n",
      "learning rate: 0.01\n",
      "1429\n",
      "learning rate: 0.01\n",
      "1536\n",
      "learning rate: 0.01\n",
      "1535\n",
      "learning rate: 0.01\n",
      "1369\n",
      "learning rate: 0.01\n",
      "1308\n",
      "learning rate: 0.01\n",
      "1222\n",
      "learning rate: 0.01\n",
      "1401\n",
      "learning rate: 0.01\n",
      "1271\n",
      "learning rate: 0.01\n",
      "1436\n",
      "learning rate: 0.01\n",
      "1178\n",
      "learning rate: 0.01\n",
      "1666\n",
      "learning rate: 0.01\n",
      "1463\n",
      "learning rate: 0.01\n",
      "1395\n",
      "learning rate: 0.01\n",
      "1786\n",
      "learning rate: 0.01\n",
      "1234\n",
      "learning rate: 0.01\n",
      "1556\n",
      "learning rate: 0.01\n",
      "1055\n",
      "learning rate: 0.01\n",
      "1730\n",
      "learning rate: 0.01\n",
      "870\n",
      "learning rate: 0.01\n",
      "1409\n",
      "learning rate: 0.01\n",
      "1443\n",
      "learning rate: 0.01\n",
      "1272\n",
      "learning rate: 0.01\n",
      "1583\n",
      "learning rate: 0.01\n",
      "1333\n",
      "learning rate: 0.01\n",
      "915\n",
      "learning rate: 0.01\n",
      "1359\n",
      "learning rate: 0.01\n",
      "1783\n",
      "learning rate: 0.01\n",
      "1227\n",
      "learning rate: 0.01\n",
      "1511\n",
      "learning rate: 0.01\n",
      "1532\n",
      "learning rate: 0.01\n",
      "1511\n",
      "learning rate: 0.01\n",
      "1185\n",
      "learning rate: 0.01\n",
      "1760\n",
      "learning rate: 0.01\n",
      "1589\n",
      "learning rate: 0.01\n",
      "1240\n",
      "learning rate: 0.01\n",
      "1155\n",
      "learning rate: 0.01\n",
      "1346\n",
      "learning rate: 0.01\n",
      "1623\n",
      "learning rate: 0.01\n",
      "1514\n",
      "learning rate: 0.01\n",
      "1561\n",
      "learning rate: 0.01\n",
      "1566\n",
      "learning rate: 0.01\n",
      "1271\n",
      "learning rate: 0.01\n",
      "1573\n",
      "learning rate: 0.01\n",
      "1554\n",
      "learning rate: 0.01\n",
      "1368\n",
      "learning rate: 0.01\n",
      "1419\n",
      "learning rate: 0.01\n",
      "1487\n",
      "learning rate: 0.01\n",
      "1579\n",
      "learning rate: 0.01\n",
      "1464\n",
      "learning rate: 0.01\n",
      "1823\n",
      "learning rate: 0.01\n",
      "1644\n",
      "learning rate: 0.01\n",
      "1217\n",
      "learning rate: 0.01\n",
      "1440\n",
      "learning rate: 0.01\n",
      "915\n",
      "learning rate: 0.01\n",
      "1857\n",
      "learning rate: 0.01\n",
      "1456\n",
      "learning rate: 0.01\n",
      "684\n",
      "learning rate: 0.01\n",
      "1381\n",
      "learning rate: 0.01\n",
      "1278\n",
      "learning rate: 0.01\n",
      "1228\n",
      "learning rate: 0.01\n",
      "1246\n",
      "learning rate: 0.01\n",
      "1706\n",
      "learning rate: 0.01\n",
      "1401\n",
      "learning rate: 0.01\n",
      "1259\n",
      "learning rate: 0.01\n",
      "1516\n",
      "learning rate: 0.01\n",
      "1723\n",
      "learning rate: 0.01\n",
      "1175\n",
      "learning rate: 0.01\n",
      "1479\n",
      "learning rate: 0.01\n",
      "1412\n",
      "learning rate: 0.01\n",
      "1191\n",
      "learning rate: 0.01\n",
      "1462\n",
      "learning rate: 0.01\n",
      "1484\n",
      "learning rate: 0.01\n",
      "1541\n",
      "learning rate: 0.01\n",
      "1806\n",
      "learning rate: 0.01\n",
      "1561\n",
      "learning rate: 0.01\n",
      "1612\n",
      "learning rate: 0.01\n",
      "1299\n",
      "learning rate: 0.01\n",
      "1033\n",
      "learning rate: 0.01\n",
      "856\n",
      "TEST MSE\n",
      "[0.17857142857142858, 0.17346938775510204, 0.1989795918367347, 0.24489795918367346, 0.18877551020408162, 0.14285714285714285, 0.14285714285714285, 0.15306122448979592, 0.20408163265306123, 0.22959183673469388, 0.17346938775510204, 0.15816326530612246, 0.18877551020408162, 0.18877551020408162, 0.17346938775510204, 0.1989795918367347, 0.24489795918367346, 0.20918367346938777, 0.19387755102040816, 0.15816326530612246, 0.22448979591836735, 0.15816326530612246, 0.24489795918367346, 0.15306122448979592, 0.24489795918367346, 0.20918367346938777, 0.24489795918367346, 0.1683673469387755, 0.24489795918367346, 0.24489795918367346, 0.19387755102040816, 0.24489795918367346, 0.21428571428571427, 0.18877551020408162, 0.23979591836734693, 0.24489795918367346, 0.18877551020408162, 0.1836734693877551, 0.17857142857142858, 0.20918367346938777, 0.20918367346938777, 0.19387755102040816, 0.18877551020408162, 0.23469387755102042, 0.16326530612244897, 0.18877551020408162, 0.1683673469387755, 0.17857142857142858, 0.12755102040816327, 0.24489795918367346, 0.18877551020408162, 0.14795918367346939, 0.17857142857142858, 0.15306122448979592, 0.14285714285714285, 0.20918367346938777, 0.16326530612244897, 0.1836734693877551, 0.22448979591836735, 0.1836734693877551, 0.23469387755102042, 0.15816326530612246, 0.14285714285714285, 0.23469387755102042, 0.21428571428571427, 0.1836734693877551, 0.18877551020408162, 0.1683673469387755, 0.20408163265306123, 0.1377551020408163, 0.17857142857142858, 0.1683673469387755, 0.20918367346938777, 0.23469387755102042, 0.1989795918367347, 0.24489795918367346, 0.1683673469387755, 0.23469387755102042, 0.22959183673469388, 0.18877551020408162, 0.20918367346938777, 0.1683673469387755, 0.18877551020408162, 0.21428571428571427, 0.1377551020408163, 0.17346938775510204, 0.24489795918367346, 0.21428571428571427, 0.24489795918367346, 0.1989795918367347, 0.24489795918367346, 0.20918367346938777, 0.12244897959183673, 0.17346938775510204, 0.1989795918367347, 0.16326530612244897, 0.17346938775510204, 0.1683673469387755, 0.16326530612244897, 0.24489795918367346, 0.18877551020408162]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x1c73d9b8ef0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c73d9b8fd0>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x1c73d9c9780>,\n",
       "  <matplotlib.lines.Line2D at 0x1c73d9c9ba8>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x1c73d9b8978>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x1c73d9c9fd0>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x1c73d9d3438>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------Method for different values of weight generation and MSE calculation- 100 TIMES--------------\n",
    "def model(X_train, y_train, X_test, y_test, num_iterations, learning_rate, print_cost = False):\n",
    "    # Bias\n",
    "    b = np.ones((X_train.shape[0], 1)) \n",
    "    X_train = np.concatenate((b, X_train), axis=1)\n",
    "    X_test = np.concatenate((b, X_test), axis=1)\n",
    "    #    np.random.seed(1)\n",
    "    \n",
    "    #Different values of Independent number generation for weight between [-0.7 0.7]\n",
    "    w = np.random.uniform(low=-0.7,high=0.7,size=(X_train.shape[1],))\n",
    "    print(\"learning rate:\",learning_rate) \n",
    "\n",
    "    # optimize and finding the model with best suited Weights and bias\n",
    "    parameters, grads, costs = optimize(w, b, X_train, y_train, num_iterations, learning_rate, print_cost = False)\n",
    "\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "\n",
    "    # Predict both train and test against optimized weights and Bias\n",
    "    Y_prediction_train = predict(w,b,X_train)\n",
    "    Y_prediction_test = predict(w,b,X_test)\n",
    "\n",
    "    Y_hat_train = list(Y_prediction_train)\n",
    "    y_train_m = list(y_train)\n",
    "    y_test_m = list(y_test)\n",
    "    Y_hat_test = list(Y_prediction_test)  \n",
    "      \n",
    "    # MSE calculation - for both TRAIN and TEST\n",
    "    a=0\n",
    "    correct=0\n",
    "    for each_train in y_train_m:\n",
    "        if each_train-Y_hat_train[a]!=0:\n",
    "            correct+=1\n",
    "        a+=1\n",
    "    curr_mse_train = correct/len(y_train_m)\n",
    "\n",
    "    a1=0\n",
    "    correct1=0\n",
    "    for each_test in y_test_m:\n",
    "        if each_test-Y_hat_test[a1]!=0:\n",
    "            correct1+=1\n",
    "        a1+=1\n",
    "    curr_mse_test = correct1/len(y_test_m)\n",
    "\n",
    "    d = {\"train MSE\": curr_mse_train,\n",
    "        \"test MSE\": curr_mse_test}\n",
    "    \n",
    "#    plt.boxplot(curr_mse_test)\n",
    "    \n",
    "    return d\n",
    "\n",
    "\n",
    "# --------------------Main Call for functions implementation------------------\n",
    "result_train = []\n",
    "result_test = []\n",
    "\n",
    "# Running the model and getting MSE for Epochs - 5000 and Learning Rate - 0.01 (100 times)\n",
    "for i in range(101):\n",
    "    d = model(X_train, y_train, X_test, y_test, num_iterations = 5000, learning_rate = 0.01, print_cost = True)\n",
    "    result_train.append(d[\"train MSE\"])\n",
    "    result_test.append(d[\"test MSE\"])              \n",
    "\n",
    "print(\"TEST MSE\")\n",
    "print(result_test)\n",
    "\n",
    "#  Boxplot for test MSE\n",
    "plt.boxplot(result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
